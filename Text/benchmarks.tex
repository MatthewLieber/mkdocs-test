\section{OSU Benchmarks}
\label{sec:osubenchmarks}

If you have arrived at this point, you have successfully installed MVAPICH2.
Congratulations!! The OSU benchmarks should already be built and installed
along with MVAPICH2. Look for them under \$prefix/libexec/mvapich2.
Sample performance numbers for these benchmarks on representative platforms
with InfiniBand, iWARP and RoCE adapters are also included on our projects' web
page. You are welcome to compare your performance numbers with our numbers.  
If you see any big discrepancy, please let us know by sending an email to
\href{mailto:mvapich-discuss@cse.ohio-state.edu}{mvapich-discuss@cse.ohio-state.edu}.
 
The benchmarks provided are:

\begin{center}
\begin{tabular}{ll}
\multicolumn{2}{c}{MPI-1, MPI-2 and MPI-3}\\
\hline
osu\_bibw & Bidirectional Bandwidth Test\\
osu\_bw & Bandwidth Test\\
osu\_latency & Latency Test\\
osu\_latency\_mt & Multi-threaded Latency Test \\
osu\_mbw\_mr & Multiple Bandwidth / Message Rate Test\\
osu\_multi\_lat & Multi-pair Latency Test\\
osu\_allgather & MPI\_Allgather Latency Test \\
osu\_allgatherv & MPI\_Allgatherv Latency Test\\
osu\_allreduce & MPI\_Allreduce Latency Test\\
osu\_alltoall & MPI\_Alltoall Latency Test\\
osu\_alltoallv & MPI\_Alltoallv Latency Test\\
osu\_barrier & MPI\_Barrier Latency Test\\
osu\_bcast & MPI\_Bcast Latency Test\\
osu\_gather & MPI\_Gather Latency Test \\ 
osu\_gatherv & MPI\_Gatherv Latency Test\\
osu\_reduce & MPI\_Reduce Latency Test\\
osu\_reduce\_scatter & MPI\_Reduce\_scatter Latency Test\\
osu\_scatter & MPI\_Scatter Latency Test\\
osu\_scatterv & MPI\_Scatterv Latency Test\\
&\\
\multicolumn{2}{c}{MPI-2 and MPI-3 only}\\
\hline
osu\_acc\_latency & Accumulate Latency Test with Active/Passive Synchronization\\
osu\_get\_bw & One-Sided Get Bandwidth Test with Active/Passive Synchronization\\
osu\_get\_latency & One-Sided Get Latency Test with Active/Passive Synchronization\\
osu\_latency\_mt & Multi-threaded Latency Test\\
osu\_put\_bibw & One-Sided Put Bidirectional Test with Active Synchronization\\
osu\_put\_bw & One-Sided Put Bandwidth Test with Active/Passive Synchronization\\
osu\_put\_latency & One-Sided Put Latency Test with Active/Passive Synchronization\\
&\\
\multicolumn{2}{c}{MPI-3 only}\\
\hline
osu\_cas\_latency & One-Sided Compare\_and\_swap Latency Test with
Active/Passive Synchronization\\
osu\_fop\_latency & One-Sided Fetch\_and\_op Latency Test with Active/Passive
Synchronization\\
osu\_get\_acc\_latency & One-Sided Get\_accumulate Latency Test with
Active/Passive Synchronization\\
osu\_iallgather & MPI\_Iallgather Latency Test \\
osu\_iallgatherv & MPI\_Iallgatherv Latency Test \\
osu\_iallreduce & MPI\_Iallreduce Latency Test \\
osu\_ialltoall & MPI\_Ialltoall Latency Test \\
osu\_ialltoallv & MPI\_Ialltoallv Latency Test \\
osu\_ialltoallw & MPI\_Ialltoallw Latency Test \\
osu\_ibarrier & MPI\_Ibarrier Latency Test \\
osu\_ibcast & MPI\_Ibcast Latency Test \\
osu\_igather & MPI\_Igather Latency Test \\
osu\_igatherv & MPI\_Igatherv Latency Test \\
osu\_ireduce & MPI\_Ireduce Latency Test \\
osu\_iscatter & MPI\_Iscatter Latency Test \\
osu\_iscatterv & MPI\_Iscatterv Latency Test \\
&\\

\end{tabular}
\end{center}

\noindent More information about the benchmarks can be found at
\href{http://mvapich.cse.ohio-state.edu/benchmarks/}{http://mvapich.cse.ohio-state.edu/benchmarks/}.
You can also check this link for updates to the benchmarks.

\subsection{Download and Build Stand-alone OSU Benchmarks Package} 

The OSU Benchmarks can also be downloaded as a separate package from
\href{http://mvapich.cse.ohio-state.edu/benchmarks/}{here}.
You can build the benchmarks using the following steps if
mpicc is in your PATH. For example:

\CommandBox{\$ ./configure --prefix=<path-to-install> \&\& make \&\& make install}{0.9}

\noindent If mpicc is not in your path or you would like to use another particular
version you can explicitly tell configure by setting CC. For example:

\CommandBox{\$ ./configure CC=/path/to/special/mpicc --prefix=<path-to-install> \&\& make \&\& make install\\}{0.9}

\noindent Configure will detect whether your library supports MPI-2, MPI-3 and
compile the corresponding benchmarks. The benchmarks will be installed under 
\$prefix/libexec/osu-micro-benchmarks.

\noindent CUDA Extensions to OMB can be enabled by configuring the benchmark
suite with --enable-cuda option as shown below.  Similarly, OpenACC Extensions
can be enabled by specifying the --enable-openacc option.  The MPI library used
should be able to support MPI communication from buffers in GPU Device memory.

\CommandBox{\$ ./configure CC=/path/to/mpicc \\
    \hspace*{3em} --enable-cuda \\
    \hspace*{3em} --with-cuda-include=/path/to/cuda/include \\
    \hspace*{3em} --with-cuda-lib=/path/to/cuda/lib \\
\$ make \\
\$ make install}{0.7}

\subsection{Running}
The OSU Benchmarks are run in the same manner as other MPI Applications.  The
following examples will use mpirun\_rsh as the process manager.  Please see
section~\ref{sec:run-applications} for more information on running with other
process managers.

\subsubsection{Running OSU Latency and Bandwidth}

\noindent\textbf{Inter-node latency and bandwidth:} The following
example will measure the latency and bandwidth of communication between
node1 and node2.

\CommandBox{\$ mpirun\_rsh -np 2 node1 node2 ./osu\_latency}{0.7}

\CommandBox{\$ mpirun\_rsh -np 2 node1 node2 ./osu\_bw}{0.7}

\noindent\textbf{Intra-node latency and bandwidth:} The following
example will measure the latency and bandwidth of communication inside
node1 on different cores. This assumes that you have at least two cores
(or processors) in your node.

\CommandBox{\$ mpirun\_rsh -np 2 node1 node1 ./osu\_latency}{0.7}

\CommandBox{\$ mpirun\_rsh -np 2 node1 node1 ./osu\_bw}{0.7}

\subsubsection{Running OSU Message Rate Benchmark}

\noindent The OSU message rate benchmark reports the rate at which
messages can be sent between two nodes. It is advised that it should be
run in a configuration that utilizes multiple pairs of communicating
processes on two nodes. The following example measures the message rate
on a system with two nodes, each with four processor cores.

\CommandBox{\$ mpirun\_rsh -np 8 -hostfile mf ./osu\_mbw\_mr}{0.7}

\noindent Where hostfile ``mf'' has the following contains:

\noindent node1\\
node1\\
node1\\
node1\\
node2\\
node2\\
node2\\
node2\\

\subsubsection{Running OSU Collective Benchmarks}
\noindent By default, the OSU collective benchmarks report the average
communication latencies for a given collective operation, across various message lengths. 
Additionally, the benchmarks offer the following options:
\begin{enumerate}
    \item "-f" can be used to report additional statistics,
           such as min and max latencies and the number of iterations.
    \item "-m" option can be used to set the maximum message length to be used in a
           benchmark. In the default version, the benchmarks report the
           latencies for up to 1MB message lengths.
    \item "-i" can be used to set the number of iterations to run for each message
           length.
    \item "-h" can be used to list all the options and their descriptions. 
    \item "-v" reports the benchmark version. 
\end{enumerate}


If a user wishes to measure the communication latency of a specific collective operation,
say, MPI\_Alltoall, with 16 processes, we recommend running the osu\_alltoall
benchmark in the following manner: 

\CommandBox{\$ mpirun\_rsh -np 16 -hostfile mf ./osu\_alltoall}{0.7}

\noindent Where hostfile ``mf'' has the following contains:

\noindent node1\\
node1\\
node1\\
node1\\
node1\\
node1\\
node1\\
node1\\
node1\\
node2\\
node2\\
node2\\
node2\\
node2\\
node2\\
node2\\
node2\\

\subsubsection{Running Benchmarks with CUDA/OpenACC/ROCm Extensions}
\noindent The following benchmarks have been extended to evaluate performance
of MPI communication from and to buffers on NVIDIA GPU devices.

\begin{center}
\begin{tabular}{ll}
osu\_bibw & Bidirectional Bandwidth Test\\
osu\_bw & Bandwidth Test\\
osu\_latency & Latency Test\\
osu\_latency\_mt & Multi-threaded Latency Test\\
osu\_mbw\_mr & Multiple Bandwidth / Message Rate Test \\
osu\_multi\_lat & Multi-pair Letency Test \\ 
osu\_put\_latency & Latency Test for Put \\
osu\_get\_latency & Latency Test for Get \\
osu\_put\_bw & Bandwidth Test for Put \\
osu\_get\_bw & Bandwidth Test for Get \\
osu\_put\_bibw & Bidirectional Bandwidth Test for Put \\
osu\_acc\_latency & Latency Test for Accumulate \\
osu\_cas\_latency & Latency Test for Compare and Swap \\
osu\_fop\_latency & Latency Test for Fetch and Op \\
osu\_allgather & MPI\_Allgather Latency Test \\
osu\_allgatherv & MPI\_Allgatherv Latency Test \\
osu\_allreduce & MPI\_Allreduce Latency Test \\
osu\_alltoall & MPI\_Alltoall Latency Test \\
osu\_alltoallv & MPI\_Alltoallv Latency Test \\
osu\_bcast & MPI\_Bcast Latency Test \\
osu\_gather & MPI\_Gather Latency Test \\ 
osu\_gatherv & MPI\_Gatherv Latency Test \\
osu\_reduce & MPI\_Reduce Latency Test \\
osu\_reduce\_scatter & MPI\_Reduce\_scatter Latency Test \\
osu\_scatter & MPI\_Scatter Latency Test \\
osu\_scatterv & MPI\_Scatterv Latency Test \\
osu\_iallgather & MPI\_Iallgather Latency Test \\
osu\_iallreduce & MPI\_Iallreduce Latency Test \\
osu\_ialltoall & MPI\_Ialltoall Latency Test \\
osu\_ibcast & MPI\_Ibcast Latency Test \\
osu\_igather & MPI\_Igather Latency Test \\
osu\_ireduce & MPI\_Ireduce Latency Test \\
osu\_iscatter & MPI\_Iscatter Latency Test
\end{tabular}
\end{center}

\noindent Each of the pt2pt benchmarks takes two input parameters. The first
parameter indicates the location of the buffers at rank 0 and the second
parameter indicates the location of the buffers at rank 1. The value of each of
these parameters can be either 'H' or 'D' to indicate if the buffers are to be
on the host or on the device, respectively. When no parameters are specified,
the buffers are allocated on the host.

The collective benchmarks will use buffers allocated on the device if the -d option is used otherwise the buffers will be allocated on the host.

If both CUDA and OpenACC support is enabled, you can switch between using CUDA
and OpenACC to allocate your device buffers by specifying the '-d cuda' or '-d
openacc' option to the benchmark.  Please use the '-h' option for more info.

GPU affinity for processes is set before MPI\_Init is called.  The
process rank on a node is normally used to do this and different MPI launchers
expose this information through different environment variables. The benchmarks
use an environment variable called LOCAL\_RANK to get this information. 
The script like get\_local\_rank provided alongside the benchmarks can be used 
to export this environment variable when using mpirun\_rsh. This can be adapted 
to work with other MPI launchers and libraries.

\noindent\textbf{Examples:}

\CommandBox{\$ mpirun\_rsh -np 2 host0 host0 MV2\_USE\_CUDA=1 get\_local\_rank ./osu\_latency D D}{0.7}

\noindent In this run, assuming host0 has two GPU devices, the latency test
allocates buffers on GPU device 0 at rank 0 and on GPU device 1 at rank 1.

\CommandBox{\$ mpirun\_rsh -np 2 host0 host1 MV2\_USE\_CUDA=1 get\_local\_rank ./osu\_bw D H}{0.7}

\noindent In this run, the bandwidth test allocates buffers on the GPU device at rank 0 (host0) 
and on the host at rank 1 (host1). 

\subsubsection{Running Benchmarks with CUDA Managed Memory}
\noindent The following benchmarks have been extended to evaluate performance
of MPI communication from and to buffers allocated using CUDA Managed Memory.

\begin{center}
\begin{tabular}{ll}
osu\_bibw & Bidirectional Bandwidth Test\\
osu\_bw & Bandwidth Test\\
osu\_latency & Latency Test\\
osu\_mbw\_mr & Multiple Bandwidth / Message Rate Test \\
osu\_multi\_lat & Multi-pair Letency Test \\ 
osu\_allgather & MPI\_Allgather Latency Test \\
osu\_allgatherv & MPI\_Allgatherv Latency Test \\
osu\_allreduce & MPI\_Allreduce Latency Test \\
osu\_alltoall & MPI\_Alltoall Latency Test \\
osu\_alltoallv & MPI\_Alltoallv Latency Test \\
osu\_bcast & MPI\_Bcast Latency Test \\
osu\_gather & MPI\_Gather Latency Test \\ 
osu\_gatherv & MPI\_Gatherv Latency Test \\
osu\_reduce & MPI\_Reduce Latency Test \\
osu\_reduce\_scatter & MPI\_Reduce\_scatter Latency Test \\
osu\_scatter & MPI\_Scatter Latency Test \\
osu\_scatterv & MPI\_Scatterv Latency Test \\
\end{tabular}
\end{center}

\noindent In addition to support for communications to and from GPU memories allocated 
using CUDA or OpenACC, we now provide additional capability of performing communications 
to and from buffers allocated using the CUDA Managed Memory concept. CUDA Managed (or Unified) 
Memory allows applications to allocate memory on either CPU or GPU memories using the 
cudaMallocManaged() call. This allows user oblivious transfer of the memory buffer between the 
CPU or GPU. Currently, we offer benchmarking with CUDA Managed Memory using the tests mentioned 
above. These benchmarks have additional options: "M" allocates a send or receive buffer as 
managed for point to point communication. "-d managed" uses managed memory buffers to perform 
collective communications

\begin{comment}
\subsection{Benchmark Description}
\subsubsection{Latency Test}
The latency tests were carried out in a ping-pong fashion.  The sender sends a
message with a certain data size to the receiver and waits for a reply from the
receiver.  The receiver receives the message from the sender and sends back a
reply with the same data size.  Many iterations of this ping-pong test were
carried out and average one-way latency numbers were obtained.  Blocking
version of MPI functions (MPI\_Send and MPI\_Recv) were used in the tests.

\subsubsection{Multi-threaded Latency Test}
Only applicable for MVAPICH2 with threading support enabled.  The
multi-threaded latency test performs a ping-pong test with a single sender
process and multiple threads on the receiving process.  In this test the
sending process sends a message of a given data size to the receiver and waits
for a reply from the receiver process.  The receiving process has a variable
number of receiving threads (set by default to 2), where each thread calls
MPI\_Recv and upon receiving a message sends back a response of equal size.
Many iterations are performed and the average one-way latency numbers are
reported.

\subsubsection{Bandwidth Test}
The bandwidth tests were carried out by having the sender sending out a fixed
number (equal to the window size) of back-to-back messages to the receiver and
then waiting for a reply from the receiver.  The receiver sends the reply only
after receiving all these messages.  This process is repeated for several
iterations and the bandwidth is calculated based on the elapsed time (from the
time sender sends the first message until the time it receives the reply back
from the receiver) and the number of bytes sent by the sender.  The objective
of this bandwidth test is to determine the maximum sustained date rate that can
be achieved at the network level.  Thus, non-blocking version of MPI functions
(MPI\_Isend and MPI\_Irecv) were used in the test.

\subsubsection{Bidirectional Bandwidth Test}
The bidirectional bandwidth test is similar to the bandwidth test, except that
both the nodes involved send out a fixed number of back-to-back messages and
wait for the reply.  This test measures the maximum sustainable aggregate
bandwidth by two nodes.

\subsubsection{Multiple Bandwidth / Message Rate test}
The multi-pair bandwidth and message rate test evaluates the aggregate
uni-directional bandwidth and message rate between multiple pairs of processes.
Each of the sending processes sends a fixed number of messages (the window
size) back-to-back to the paired receiving process before waiting for a reply
from the receiver.  This process is repeated for several iterations.  The
objective of this benchmark is to determine the achieved bandwidth and message
rate from one node to another node with a configurable number of processes
running on each node.

\subsubsection{Multi-pair Latency Test}
This test is very similar to the latency test.  However, at the same instant
multiple pairs are performing the same test simultaneously.  In order to
perform the test across just two nodes the hostnames must be specified in block
fashion.


\subsubsection{One-Sided Put Latency Test}
The sender (origin process) calls MPI\_Put (ping) to directly place a message
of certain data size in the receiver window.  The receiver (target process)
calls MPI\_Win\_wait to make sure the message has been received.  Then the
receiver initiates a MPI\_Put (pong) of the same data size to the sender which
is now waiting on a synchronization call.  Several iterations of this test is
carried out and the average put latency numbers is obtained.

\subsubsection{One-Sided Get Latency Test}
The origin process calls MPI\_Get (ping) to directly fetch a message of certain
data size from the target process window to its local window.  It then waits on
a synchronization call (MPI\_Win\_complete) for local completion.  After the
synchronization call the target and origin process are switched for the pong
message.  Several iterations of this test are carried out and the average get
latency numbers is obtained.

\subsubsection{One-Sided Put Bandwidth Test}
The bandwidth tests were carried out by the origin process calling a fixed
number of back to back Puts and then wait on a synchronization call
(MPI\_Win\_complete) for completion.  This process is repeated for several
iterations and the bandwidth is calculated based on the elapsed time and the
number of bytes sent by the origin process.

\subsubsection{One-Sided Get Bandwidth Test}
The bandwidth tests were carried out by origin process calling a fixed number
of back to back Gets and then wait on a synchronization call
(MPI\_Win\_complete) for completion.  This process is repeated for several
iterations and the bandwidth is calculated based on the elapsed time and the
number of bytes sent by the origin process.

\subsubsection{One-Sided Put Bidirectional Bandwidth Test}
The bidirectional bandwidth test is similar to the bandwidth test,except that
both the nodes involved send out a fixed number of back to back put messages
and wait for the completion.  This test measures the maximum sustainable
aggregate bandwidth by two nodes.

\subsubsection{Accumulate Latency Test}
The origin process calls MPI\_Accumulate to combine the data moved to the
target process window with the data that resides at the remote window.  The
combining operation used in the test is MPI\_SUM.  It then waits on a
synchronization call (MPI\_Win\_complete) for local completion.  After the
synchronization call, the target and origin process are switched for the pong
message.  Several iterations of this test are carried out and the average
accumulate latency number is obtained.

\subsubsection{Collective Latency Tests}
The latest OMB Version includes benchmarks for various MPI-1, MPI-2 and MPI-3 collective
operations (MPI\_Bcast, MPI\_Reduce, MPI\_Allreduce, MPI\_Alltoall, MPI\_Allgather,
MPI\_Scatter, MPI\_Gather, MPI\_Reduce\_Scatter,
MPI\_Barrier and vector variants). These benchmarks work in
the following manner. Suppose users run the osu\_bcast benchmark with N
processes, the benchmark measures the min, max and the average latency of the MPI\_Bcast
collective operation across N processes, for various message lengths. The
averages are computed across a large number of iterations (1000).

\end{comment}
