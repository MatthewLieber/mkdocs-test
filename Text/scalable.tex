\section{Scalability features and Performance Tuning for Large Scale Clusters}
\label{sec:performance-tuning}

MVAPICH2 provides many different parameters for tuning performance for a
wide variety of platforms and applications. This section deals with
tuning CH3-based interfaces. These parameters can be either compile time
parameters or runtime parameters. Please refer to
Section~\ref{sec:performance-tuning} for a complete description of all
these parameters.  In this section we classify these parameters
depending on what you are tuning for and provide guidelines on how to
use them.

\subsection{Optimizations for homogeneous clusters}

MVAPICH2 internally detects the heterogeneity of the cluster in terms of 
processor and network interface type. Set parameter MV2\_HOMOGENEOUS\_CLUSTER to 1 
to skip this detection, if the user already knows that cluster is homogeneous.

\subsection{Improving Job startup performance}

MVAPICH2 has several advanced features to speed up launching jobs on
HPC clusters. There are several launcher-agnostic and launcher-specific
parameters that can be used to get the best job startup performance. More
details about these designs can be obtained from:
\url{http://mvapich.cse.ohio-state.edu/performance/job-startup/} 

\subsubsection{Configuration Options (Launcher-Agnostic)}

\begin{itemize}
\item Disabling RDMA\_CM
    \begin{itemize}
        \item Default: Enabled
        \item Disable: \texttt{--disable-rdma-cm}
        \item Disabling RDMA\_CM will improve job-startup performance,
            particularly on nodes with large number of cores.
    \end{itemize}
\end{itemize}

\subsubsection{Runtime Parameters (Launcher-Agnostic)}

\begin{itemize}
\item MV2\_HOMOGENEOUS\_CLUSTER
    \begin{itemize}
        \item Default: 0 (Disabled)
        \item Setting MV2\_HOMOGENEOUS\_CLUSTER to 1 on homogeneous clusters
            will improve startup performance.
    \end{itemize}
\item MV2\_ON\_DEMAND\_THRESHOLD 
    \begin{itemize}
        \item Default: 64 (OFA-IB-CH3), 16 (OFA-iWARP-CH3)
        \item Should be enabled for fast startup. See
            Section~\ref{def:mv2-on-demand-threshold} for details.
    \end{itemize}
\item MV2\_ON\_DEMAND\_UD\_INFO\_EXCHANGE 
    \begin{itemize}
        \item Default: 1 (Enabled)
        \item Setting MV2\_ON\_DEMAND\_UD\_INFO\_EXCHANGE to 1 
            will enable on-demand Address Handle creation for hybrid mode.
    \end{itemize}
\end{itemize}

\subsubsection{Enabling Optimizations Specific to mpirun\_rsh}

\begin{itemize}
\item \textbf{MV2\_MT\_DEGREE}:
MVAPICH2 has a scalable job launcher -- mpirun\_rsh which uses a
tree based mechanism to spawn processes. The degree of this tree is
determined dynamically to keep the depth low. For large clusters, it might
be beneficial to further flatten the tree by specifying a higher degree. The
degree can be overridden with the environment variable MV2\_MT\_DEGREE (see~\ref{def:mt-degree}).

\item \textbf{MV2\_FASTSSH\_THRESHOLD}:
MVAPICH2 can use a faster, hierarchical launching mechanism on large
clusters. This is enabled manually using
MV2\_FASTSSH\_THRESHOLD (see~\ref{def:mv2_fastssh_threshold}).

\item \textbf{MV2\_NPROCS\_THRESHOLD}:
When the number of processes involved is beyond 8k, the mpirun\_rsh uses a
file-based communication scheme to create the hierarchical tree.  The default
value can be overridden with the environment variable MV2\_NPROCS\_THRESHOLD
 (see~\ref{def:mv2_nprocs_threshold}).
\end{itemize}

\subsubsection{Enabling Optimizations Specific to SLURM}

\begin{itemize}
\item \textbf{Using OSU optimized SLURM}:
For best performance with SLURM, the OSU-optimized PMI2 plugin should be used.
This requires applying the appropriate patch to SLURM. Please refer to
Section~\ref{subsec:config-slurm-pmix} for more details.

\item \textbf{Using Default SLURM}:
If the SLURM installation cannot be modified, the default PMI2 plugin provided
by SLURM should be used. Please see section~\ref{subsec:config-slurm} for more
details.
\end{itemize}


\subsection{Basic QP Resource Tuning}
The following parameters affect memory requirements for each QP.

\begin{itemize}
\item{MV2\_DEFAULT\_MAX\_SEND\_WQE}
\item{MV2\_DEFAULT\_MAX\_RECV\_WQE}
\item{MV2\_MAX\_INLINE\_SIZE}
\end{itemize}

MV2\_DEFAULT\_MAX\_SEND\_WQE and MV2\_DEFAULT\_MAX\_RECV\_WQE 
control the maximum number of WQEs per QP and 
MV2\_MAX\_INLINE\_SIZE controls the maximum inline size. Reducing the
values of these two parameters leads to less memory consumption. They are 
especially important for large scale clusters with a large amount of connections
and multiple rails.

These two parameters are run-time adjustable. Please refer to 
Sections~\ref{def:max-send-wqe} and~\ref{def:max-inline-size} for details.


\subsection{RDMA Based Point-to-Point Tuning}
The following parameters are important in tuning the memory requirements for
adaptive rdma fast path feature.
\begin{itemize}
\item{MV2\_RDMA\_FAST\_PATH\_BUF\_SIZE} (\ref{def:rdma-fast-path-buf-size})
\item{MV2\_NUM\_RDMA\_BUFFER} (\ref{def:num-rdma-buffer})
\end{itemize}

MV2\_RDMA\_FAST\_PATH\_BUF\_SIZE is the size of each buffer used in RDMA fast path 
communication.

MV2\_NUM\_RDMA\_BUFFER is number of buffers used for the RDMA fast path communication.

On the other hand, the product of MV2\_RDMA\_FAST\_PATH\_BUF\_SIZE and \\
MV2\_NUM\_RDMA\_BUFFER generally is a measure of the amount of memory registered
for eager message passing. These buffers are not shared across connections.

\subsection{Shared Receive Queue (SRQ) Tuning}

The main environmental parameters controlling the behavior of the Shared
Receive Queue design are:

\begin{itemize}
    \item MV2\_SRQ\_MAX\_SIZE
        (\ref{def:viadev-srq-max-size})
    \item MV2\_SRQ\_SIZE
        (\ref{def:viadev-srq-size})
    \item MV2\_SRQ\_LIMIT
        (\ref{def:viadev-srq-limit})
\end{itemize}

MV2\_SRQ\_MAX\_SIZE is the maximum size of the Shared Receive Queue (default 4096).
You may increase this to value 8192 if the application requires very large number 
of processors. The application will start by only using MV2\_SRQ\_SIZE buffers 
(default 256) and will double this value on every SRQ limit event(upto MV2\_SRQ\_MAX\_SIZE).
For long running applications this re-size should show little effect. If needed, the MV2\_SRQ\_SIZE
can be increased to 1024 or higher as needed for applications. \\
MV2\_SRQ\_LIMIT defines the low water-mark for the
flow control handler. This can be reduced if your aim is to reduce the number of
interrupts.

\subsection {eXtended Reliable Connection (XRC)}

MVAPICH2 now supports the eXtended Reliable Connection (XRC) transport
available in recent Mellanox HCAs. This transport helps reduce the number of
QPs needed on multi-core systems. Set MV2\_USE\_XRC (\ref{def:mv2_use_xrc})
to use XRC with MVAPICH2.

\subsection {Shared Memory Tuning}
MVAPICH2 uses shared memory communication channel to achieve high-performance
message passing among processes that are on the same physical node. The two main
parameters which are used for tuning shared memory performance for small messages are
SMP\_QUEUE\_LENGTH (Section~\ref{def:smp-queue-length}), and
SMP\_EAGER\_SIZE (Section~\ref{def:smp-eagersize}). The two main
parameters which are used for tuning shared memory performance for large messages are
SMP\_SEND\_BUF\_SIZE (Section~\ref{def:smp-send-buf-size}) and \\
SMP\_NUM\_SEND\_BUFFER
(Section~\ref{def:smp-num-send-buffer}).

SMP\_QUEUE\_LENGTH is the size of the shared memory buffer which is used to store
outstanding small and control messages. SMP\_EAGER\_SIZE defines the
switch point from Eager protocol to Rendezvous protocol.

Messages larger than SMP\_EAGER\_SIZE are packetized and sent out in a pipelined manner.
\\SMP\_SEND\_BUF\_SIZE is the packet size, i.e. the send buffer size. SMP\_NUM\_SEND\_BUFFER
is the number of send buffers.

\subsection {On-demand Connection Management Tuning} MVAPICH2 uses
on-demand connection management to reduce the memory usage of MPI
library. There are 4 parameters to tune connection manager:
MV2\_ON\_DEMAND\_THRESHOLD
(Section~\ref{def:mv2-on-demand-threshold}),\\
MV2\_CM\_RECV\_BUFFERS (Section~\ref{def:mv2-cm-recv-buffers}),
MV2\_CM\_TIMEOUT (Section~\ref{def:mv2-cm-timeout}), and\\
MV2\_CM\_SPIN\_COUNT (Section~\ref{def:mv2-cm-spin-count}). The first
one applies to OFA-IB-CH3 and OFA-iWARP-CH3 interfaces and
the other three only apply to OFA-IB-CH3 interface.

MV2\_ON\_DEMAND\_THRESHOLD defines threshold for enabling on-demand
connection management scheme. When the size of the job is larger
than the threshold value, on-demand connection management will be
used.

MV2\_CM\_RECV\_BUFFERS defines the number of buffers used by
connection manager to establish new connections. These buffers are
quite small and are shared for all connections, so this value may be
increased to 8192 for large clusters to avoid retries in case of
packet drops.

MV2\_CM\_TIMEOUT is the timeout value associated with connection
management messages via UD channel. Decreasing this value may lead
to faster retries but at the cost of generating duplicate messages.

MV2\_CM\_SPIN\_COUNT is the number of the connection manager
polls for new control messages from UD channel for each interrupt.
This may be increased to reduce the interrupt overhead when many
incoming control messages from UD channel at the same time.

\subsection{Scalable Collectives Tuning}

MVAPICH2 uses shared memory to optimize the performance for many
collective operations: MPI\_Allreduce, MPI\_Reduce, MPI\_Barrier,
and MPI\_Bcast. 

We use shared-memory based collective for most small
and medium sized messages and fall back to the default point-to-point based
algorithms for very large messages. The upper-limits for shared-memory based 
collectives are tunable parameters that are specific to each collective 
operation. We have variables such as MV2\_SHMEM\_ALLREDUCE\_MSG (\ref{def:mv2-shmem-coll-allreduce-threshold}), 
MV2\_SHMEM\_REDUCE\_MSG (\ref{def:mv2-shmem-coll-reduce-threshold}) and  \\
MV2\_SHMEM\_BCAST\_MSG (\ref{def:mv2-shmem-coll-bcast-threshold}), for 
MPI\_Allreduce, MPI\_Reduce and MPI\_Bcast collective operations. The default
values for these variables have been set through experimental analysis on 
some of our clusters and a few large scale clusters, such as the TACC Ranger. 
Users can choose to set these variables at job-launch time to tune the collective algorithms
on different platforms. 

\subsubsection{Optimizations for MPI\_Bcast}
 MVAPICH2 supports a 2-level point-to-point tree-based
 ``Knomial'' algorithm for small messages for the MPI\_Bcast operation. MVAPICH2 also 
offers improved designs that deliver better performance for medium and large message lengths. 


\subsubsection{Optimizations for MPI\_Reduce and MPI\_Allreduce}
In this release, we have introduced new 2-level algorithms for MPI\_Reduce
and MPI\_Allreduce operations, along the same lines as MPI\_Bcast. 
Pure Shared-memory based algorithms cannot be used for larger messages
for reduction operations, because the node-leader processes become the bottleneck,
as they have to perform the reduction operation on the entire data block. 
We now rely on shared-memory algorithms for MPI\_Reduce and MPI\_Allreduce for message 
sizes set by the thresholds MV2\_SHMEM\_ALLREDUCE\_MSG (\ref{def:mv2-shmem-coll-allreduce-threshold}),
MV2\_SHMEM\_REDUCE\_MSG (\ref{def:mv2-shmem-coll-reduce-threshold}), 
the new 2-level algorithms for medium sized messages and the default
point-to-point based algorithms for large messages. We have 
introduced two new run-time variables MV2\_ALLREDUCE\_2LEVEL\_MSG (\ref{def:mv2_allreduce_2level_msg})
and MV2\_REDUCE\_2LEVEL\_MSG (\ref{def:mv2_reduce_2level_msg}) to determine when 
to fall back to the default point-to-point based algorithms.

\subsubsection{Optimizations for MPI\_Gather and MPI\_Scatter}
MVAPICH2 supports two new optimized algorithms for MPI\_Gather and MPI\_Scatter operations 
-- the ``Direct'' and the multi-core aware ``2-level'' algorithms. Both these algorithms 
perform significantly better than the default binomial-tree pattern. The ``Direct''
algorithm is however inherently not very scalable and can be used when the communicator size
is less than 1K processes. We switch over to the 2-level algorithms for larger system sizes. 
For MPI\_Gather, we use different algorithms depending of the system size. For small system sizes (up to 386 cores), we use the ``2-level'' algorithm following by the ``Direct" algorithm. 
For medium system sizes (up to 1k), we use ``Binomial'' algorithm following by the ``Direct'' algorithm. 
It's possible to set the switching point between algorithms using the 
run-time parameter MV2\_GATHER\_SWITCH\_PT (\ref{def:mv2_gather_switch_pt}). 
For MPI\_Scatter, when the system size is lower than 512 cores, we use the ``Binomial'' algorithm for small 
message sizes following by the ``2-level'' algorithm for medium message sizes and the ``Direct'' algorithm 
for large message sizes. 
Users can define the threshold for small and medium message sizes using the run-time parameters 
MV2\_SCATTER\_SMALL\_MSG (\ref{def:mv2_scatter_small_msg}) and 
MV2\_SCATTER\_MEDIUM\_MSG (\ref{def:mv2_scatter_medium_msg}).
Users can also choose to use only one of these algorithms by toggling the run-time parameters 
~\ref{def:mv2_use_direct_gather} and ~\ref{def:mv2_use_two_level_gather} for MPI\_Gather and 
~\ref{def:mv2_use_direct_scatter} and ~\ref{def:mv2_use_two_level_scatter} for MPI\_Scatter. 

\subsection{Process Placement on Multi-core platforms}

Process placement has a significant impact on performance of
applications. Depending on your application communication patterns,
various process placements can result in performance gains. In
Section~\ref{sec:usage:mv2-cpu-mapping}, we have described the usage of
``bunch'' and ``scatter'' placement modes provided by MVAPICH2. Using
these modes, one can control the placement of processes within a
particular node. Placement of processes across nodes can be controlled
by adjusting the order of MPI ranks. For example, the following command
launches jobs in block fashion.

\CommandBox{\$ mpirun\_rsh -np 4 n0 n0 n1 n1 MV2\_CPU\_BINDING\_POLICY=bunch ./a.out}{0.9}

The following command launches jobs in a cyclic fashion.

\CommandBox{\$ mpirun\_rsh -np 4 n0 n1 n0 n1 MV2\_CPU\_BINDING\_POLICY=scatter ./a.out}{0.9}

We have noted that the HPL (High-Performance Linpack) benchmark performs
better when using block distribution.

\subsection{HugePage Support}

MVAPICH2 uses HugePages(2MB) by default for communication buffers
if they are configured on the system. The run-time variable, MV2\_USE\_HUGEPAGES(~\ref{def:use-hugepage})
can be used to control the  behavior of this feature.

In order to use HugePages, Make sure HugePages are configured on all
nodes. The number of HugePages can be configured by setting
vm.nr\_hugepages kernel parameter to a suitable value.  For example, to
allocate a 1GB HugePage pool, execute(as root):
\\
\\
\CommandBox{\$ echo 512 > /proc/sys/vm/nr\_hugepages}{0.9} \\
or \\
\CommandBox{\$ sysctl -w vm.nr\_hugepages = 512}{0.9} \\

